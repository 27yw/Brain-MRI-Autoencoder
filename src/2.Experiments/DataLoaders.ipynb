{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Data Loaders and Augmentator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Image-Data-Generator\" data-toc-modified-id=\"Image-Data-Generator-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Image Data Generator</a></span><ul class=\"toc-item\"><li><span><a href=\"#SAME-DIRECTORY-from-TEST-and-TRAIN\" data-toc-modified-id=\"SAME-DIRECTORY-from-TEST-and-TRAIN-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>SAME DIRECTORY from TEST and TRAIN</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPCIONES**\n",
    "    * ImageDataGenerator + imgaug\n",
    "    * ImageDataGenerator + tf.keras.layers.experimental.preprocessing\n",
    "\n",
    "Librerias\n",
    "\n",
    "* **ImageDataGenerator:**\n",
    "   * CPU\n",
    "   * No easy Custom preprocessing techniques\n",
    "   * From directory\n",
    "   * https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator?version=nightly\n",
    "   * https://keras.io/api/preprocessing/image/#imagedatasetfromdirectory-function\n",
    "   * https://towardsdatascience.com/keras-data-generators-and-how-to-use-them-b69129ed779c\n",
    "   * https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "   * https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "   * https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/\n",
    "   * **TESTEAR**: gen.fit(X_train)\n",
    "X_train_aug = gen.flow(X_train, y_train_cat, seed=0)\n",
    " \n",
    "* **imgaug**\n",
    "     * Specifically, the ***data augmentation generator method*** takes the batches of images generated by a ImageDataGenerator for training or validation and adds to the input images the selected augmentations, preserving an original copy of them to\n",
    "     * GaussianBlur method, CutOut, CoarseDropout\n",
    "* **tf.keras.layers.experimental.preprocessing**\n",
    "    * GPU\n",
    "    * Lo de Santiago de Twitter\n",
    "    * https://keras.io/guides/preprocessing_layers/\n",
    "    * https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing\n",
    "    \n",
    "* **tf.keras.preprocessing.image.load_img**\n",
    "    * Hace qcargar imagen\n",
    "    \n",
    "    \n",
    "    https://www.kaggle.com/cdeotte/dog-autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Generator\n",
    "### SAME DIRECTORY from TEST and TRAIN\n",
    "**A0**\n",
    "```python\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(..., validation_split=0.2) # OJO set validation split\n",
    "\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(PATH,\n",
    "                                                 subset='training',\n",
    "                                                 class_mode='input', #OJOOOO,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 shuffle=True,\n",
    "                                                 #save_to_dir='dir prueba' para testear el augmentado,\n",
    "                                                 #save_format='png',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32)\n",
    "\n",
    "validation_set = validation_datagen.flow_from_directory(PATH,\n",
    "                                                        subset='validation',\n",
    "                                                        class_mode='input', #OJOOOO\n",
    "                                                        target_size = (64, 64),\n",
    "                                                        batch_size = 32)\n",
    "model = create_model()\n",
    "\n",
    "# steps_per_epoch should be (number of training images total // batch_size) \n",
    "# validation_steps should be (number of validation images total // batch_size) \n",
    "model.fit(training_set,\n",
    "          steps_per_epoch = 8000,\n",
    "          epochs = 5,\n",
    "          validation_data = validation_set,\n",
    "          validation_steps = 2000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternativa 1**:\n",
    "```python\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def image_data_generator(data_dir,\n",
    "                       data_augment=False,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       target_size=(100, 100),\n",
    "                       color_mode='rgb',\n",
    "                       class_mode='input', #OJOOOO\n",
    "                       shuffle=True):\n",
    "    if data_augment:\n",
    "        datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   validation_split=0.2,#this is the trick\n",
    "                                   horizontal_flip=True)\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    generator = datagen.flow_from_directory(data_dir,\n",
    "                                          target_size=target_size,\n",
    "                                          color_mode=color_mode,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=shuffle,\n",
    "                                          class_mode=class_mode)\n",
    "    return generator\n",
    "\n",
    "train_generator = image_data_generator('Your_DataBase_Path',data_augment=True)\n",
    "```\n",
    "**Alternativa2**\n",
    "```python\n",
    "\n",
    "train_datagen = ImageDataGenerator(..., validation_split=0.2) # OJO set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    train_data_dir='full_dataset',\n",
    "    target_size=(img_height, img_width),\n",
    "    subset='training') # OJO set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    train_data_dir='full_dataset', # OJO same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    subset='validation') # OJO set as validation data\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = nb_epochs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = ImageDataGenerator()\n",
    "validation_generator = ImageDataGenerator()\n",
    "training_images = training_generator.flow_from_directory(training_directory, class_mode='input')\n",
    "validation_images = validation_generator.flow_from_directory(validation_directory, class_mode='input')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
