{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Data Loaders and Augmentator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Image-Data-Generator\" data-toc-modified-id=\"Image-Data-Generator-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Image Data Generator</a></span></li><li><span><a href=\"#NPY-CUSTOM-KERAS-Data-Generator\" data-toc-modified-id=\"NPY-CUSTOM-KERAS-Data-Generator-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>NPY CUSTOM KERAS Data Generator</a></span><ul class=\"toc-item\"><li><span><a href=\"#Initialization-of-custom-generators\" data-toc-modified-id=\"Initialization-of-custom-generators-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Initialization of custom generators</a></span></li><li><span><a href=\"#Test-generator-with-sample-models\" data-toc-modified-id=\"Test-generator-with-sample-models-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Test generator with sample models</a></span></li><li><span><a href=\"#Evaluate-Generator\" data-toc-modified-id=\"Evaluate-Generator-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Evaluate Generator</a></span></li><li><span><a href=\"#Predict-Generator\" data-toc-modified-id=\"Predict-Generator-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Predict Generator</a></span></li><li><span><a href=\"#Example-of-what-generators-returns\" data-toc-modified-id=\"Example-of-what-generators-returns-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Example of what generators returns</a></span></li></ul></li><li><span><a href=\"#OPTIMICE-APPROACHS\" data-toc-modified-id=\"OPTIMICE-APPROACHS-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>OPTIMICE APPROACHS</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tf.Data\" data-toc-modified-id=\"Tf.Data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Tf.Data</a></span></li></ul></li><li><span><a href=\"#IMAGES---FROM-PNG\" data-toc-modified-id=\"IMAGES---FROM-PNG-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>IMAGES - FROM PNG</a></span><ul class=\"toc-item\"><li><span><a href=\"#Keras-Flow_from_directory\" data-toc-modified-id=\"Keras-Flow_from_directory-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Keras Flow_from_directory</a></span></li><li><span><a href=\"#TF.Data-from-generator\" data-toc-modified-id=\"TF.Data-from-generator-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>TF.Data from generator</a></span></li><li><span><a href=\"#TF.Data-a-mano\" data-toc-modified-id=\"TF.Data-a-mano-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>TF.Data a mano</a></span></li></ul></li><li><span><a href=\"#Tensorpack\" data-toc-modified-id=\"Tensorpack-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Tensorpack</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPCIONES**\n",
    "\n",
    "  * ImageDataGenerator + imgaug\n",
    "  * ImageDataGenerator + tf.keras.layers.experimental.preprocessing\n",
    "  * **DATAAUG:** `tf.image`\n",
    "     * https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization?version=nightly\n",
    "     * https://www.tensorflow.org/tutorials/images/data_augmentation#two_options_to_use_the_preprocessing_layers\n",
    "     * **DAUG**: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb?hl=es#scrollTo=R5fGVMqlFxF7\n",
    "   \n",
    "\n",
    "Librerias\n",
    "\n",
    "* **ImageDataGenerator:**\n",
    "   * CPU\n",
    "   * No easy Custom preprocessing techniques\n",
    "   * From directory\n",
    "   * https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator?version=nightly\n",
    "   * https://keras.io/api/preprocessing/image/#imagedatasetfromdirectory-function\n",
    "   * https://towardsdatascience.com/keras-data-generators-and-how-to-use-them-b69129ed779c\n",
    "   * https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "   * https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "   * https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/\n",
    " \n",
    "* **imgaug**\n",
    "     * Specifically, the ***data augmentation generator method*** takes the batches of images generated by a ImageDataGenerator for training or validation and adds to the input images the selected augmentations, preserving an original copy of them to\n",
    "     * GaussianBlur method, CutOut, CoarseDropout\n",
    "* **tf.keras.layers.experimental.preprocessing**\n",
    "    * GPU\n",
    "    * Lo de Santiago de Twitter\n",
    "    * https://keras.io/guides/preprocessing_layers/\n",
    "    * https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing\n",
    "        \n",
    "    \n",
    "    https://www.kaggle.com/cdeotte/dog-autoencoder\n",
    "    https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:56:56.258788Z",
     "start_time": "2020-11-14T15:56:52.494361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first option is to turn on memory growth by calling `tf.config.experimental.set_memory_growth`, which attempts to allocate only **as much GPU memory as needed for the runtime allocation**s: it **starts out allocating very little memory**, and as the program gets run and **more GPU memory is needed, we extend the GPU memory region** allocated to the TensorFlow process. ***Note we do not release memory, since it can lead to memory fragmentation***. To turn on memory growth for a specific GPU, use the following code prior to allocating any tensors or executing any ops."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #model will be trained on GPU 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:56:56.274745Z",
     "start_time": "2020-11-14T15:56:56.259781Z"
    }
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:31:58.403082Z",
     "start_time": "2020-11-13T12:31:57.473847Z"
    }
   },
   "source": [
    "#tf.debugging.set_log_device_placement(True)\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:56:56.588144Z",
     "start_time": "2020-11-14T15:56:56.275722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.3.1',\n",
       " True,\n",
       " [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "GLOBAL_BATCH_SIZE = 8\n",
    "\n",
    "tf.__version__, tf.test.is_built_with_cuda(), tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Generator\n",
    "\n",
    "It inclues a easy api, and different ways of data load.\n",
    "\n",
    "**Downside**: \n",
    "* Only reads jpg, png... but it do not read npy files (we have stores numpy files in order to keep the original values of each pixel)\n",
    "* Preprocessing and augmentation are made in CPU\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(..., validation_split=0.2) # OJO set validation split\n",
    "\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(PATH,\n",
    "                                                 subset='training',\n",
    "                                                 class_mode='input', #OJOOOO,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 shuffle=True,\n",
    "                                                 #save_to_dir='dir prueba' para testear el augmentado,\n",
    "                                                 #save_format='png',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32)\n",
    "\n",
    "validation_set = validation_datagen.flow_from_directory(PATH,\n",
    "                                                        subset='validation',\n",
    "                                                        class_mode='input', #OJOOOO\n",
    "                                                        target_size = (64, 64),\n",
    "                                                        batch_size = 32)\n",
    "model = create_model()\n",
    "\n",
    "# steps_per_epoch should be (number of training images total // batch_size) \n",
    "# validation_steps should be (number of validation images total // batch_size) \n",
    "model.fit(training_set,\n",
    "          steps_per_epoch = 8000,\n",
    "          epochs = 5,\n",
    "          validation_data = validation_set,\n",
    "          validation_steps = 2000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPY CUSTOM KERAS Data Generator\n",
    "**We made a custom data generator to have mor control in preprocessing and data augmentation**\n",
    "\n",
    "**Returns a tuple with batch of input images (maybe augmented) on [0] and batch of output images on [1]**\n",
    "\n",
    "**X images could be augmented. Dimensions = (256,256,1) to be fitted in Convolutional Autoencoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of custom generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:56:56.604080Z",
     "start_time": "2020-11-14T15:56:56.589140Z"
    }
   },
   "outputs": [],
   "source": [
    "from my_data_loader import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:56:56.967582Z",
     "start_time": "2020-11-14T15:56:56.605100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Partition\n",
    "train_percentage = 0.85\n",
    "\n",
    "MAIN_PATH = '..'+os.path.sep+'IXI-T1'+os.path.sep+'img'+os.path.sep+'train_and_val'\n",
    "trainval_files = glob.glob(MAIN_PATH+os.path.sep+'*.npy')\n",
    "random.shuffle(trainval_files)\n",
    "\n",
    "lim = int(len(trainval_files)*train_percentage)\n",
    "train_files = trainval_files[:lim]\n",
    "validation_files = trainval_files[lim:]\n",
    "\n",
    "test_files = glob.glob('../IXI-T1/img/test/*.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:56:56.982566Z",
     "start_time": "2020-11-14T15:56:56.968579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46285, 5785)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "params = {'dim': (256,256),\n",
    "          'batch_size': GLOBAL_BATCH_SIZE,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True,\n",
    "          'std_normalization': True,\n",
    "         }\n",
    "# Generators\n",
    "train_generator = DataGenerator(train_files, **params)\n",
    "validation_generator = DataGenerator(validation_files, **params)\n",
    "\n",
    "train_generator.samples, train_generator.samples // train_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T10:58:17.506880Z",
     "start_time": "2020-11-13T10:58:17.493884Z"
    }
   },
   "source": [
    "### Test generator with sample models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:56:57.013339Z",
     "start_time": "2020-11-14T15:56:56.983224Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "def build_model_1(i_shape, batch_size):\n",
    "    input_layer = Input(shape=i_shape, batch_size=batch_size, name = \"Image\")\n",
    "    \n",
    "    #Preprocessing\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"https://www.tensorflow.org/tutorials/images/data_augmentation#apply_the_preprocessing_layers_to_the_datasets\n",
    "    resize_and_rescale = tf.keras.Sequential([\n",
    "      layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "      layers.experimental.preprocessing.Rescaling(1./255)\n",
    "    ])\n",
    "    \n",
    "    \"\"\"\n",
    "    # encoder\n",
    "    h = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    h = MaxPooling2D((2, 2), padding='same')(h)\n",
    "\n",
    "    # decoder\n",
    "    h = Conv2D(64, (3, 3), activation='relu', padding='same')(h)\n",
    "    h = UpSampling2D((2, 2))(h)\n",
    "    output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(h)\n",
    "\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "\n",
    "def build_model_2(input_shape, batch_size):\n",
    "    def autoencoder(input_img):\n",
    "        #encoder\n",
    "        #input = 256 x 256 x 1 (wide and thin)\n",
    "        conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #256 x 256 x 32\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #128 x 128 x 32\n",
    "\n",
    "        conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #128 x 128 x 64\n",
    "        conv2 = BatchNormalization()(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #64 x 64 x 64\n",
    "\n",
    "        conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #64 x 64 x 128 (small and thick)\n",
    "        conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "\n",
    "        #decoder\n",
    "        conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3)\n",
    "        conv4 = BatchNormalization()(conv4)\n",
    "        up1 = UpSampling2D((2,2))(conv4) # 128 x 128 x 128\n",
    "        \n",
    "        conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 128 x 128 x 64\n",
    "        conv5 = BatchNormalization()(conv5)\n",
    "        up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64\n",
    "        \n",
    "        decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 256 x 256 x 1\n",
    "        \n",
    "        return decoded\n",
    "\n",
    "    input_img = Input(shape = input_shape, batch_size=batch_size)\n",
    "    return Model(input_img, autoencoder(input_img))\n",
    "\n",
    "\n",
    "def build_model_3(input_shape, batch_size):\n",
    "    \n",
    "    # ENCODER\n",
    "    input_img = Input(shape=input_shape, batch_size = batch_size)  \n",
    "    x = Conv2D(48, (3, 3), activation='relu', padding='same', name = 'eCONV1')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding='same', name = 'eCONV2')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding='same', name = 'eCONV3')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    encoded = Conv2D(32, (1, 1), activation='relu', padding='same', name = 'eCONV4')(x)\n",
    "\n",
    "    # LATENT SPACE\n",
    "    latentSize = (int(input_shape[0]/8),int(input_shape[1]/8),32)\n",
    "\n",
    "    # DECODER\n",
    "    direct_input = Input(shape=latentSize, batch_size = batch_size)\n",
    "    x = Conv2D(192, (1, 1), activation='relu', padding='same', name = 'dCONV1')(direct_input)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding='same', name = 'dCONV2')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding='same', name = 'dCONV3')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(48, (3, 3), activation='relu', padding='same', name = 'dCONV4')(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name = 'to1channel')(x)\n",
    "\n",
    "    # COMPILE\n",
    "    encoder = Model(input_img, encoded, name='ENCOER')\n",
    "    decoder = Model(direct_input, decoded, name='DECODER')\n",
    "    return  Model(input_img, decoder(encoded), name='AUTOENCODER')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:56:58.143598Z",
     "start_time": "2020-11-14T15:56:57.014338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(8, 256, 256, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (8, 256, 256, 32)         320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (8, 256, 256, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (8, 128, 128, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (8, 128, 128, 64)         18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (8, 128, 128, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (8, 64, 64, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (8, 64, 64, 128)          73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (8, 64, 64, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (8, 64, 64, 64)           73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (8, 64, 64, 64)           256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (8, 128, 128, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (8, 128, 128, 32)         18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (8, 128, 128, 32)         128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (8, 256, 256, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (8, 256, 256, 1)          289       \n",
      "=================================================================\n",
      "Total params: 186,497\n",
      "Trainable params: 185,857\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder =  build_model_2((256,256,1),  train_generator.batch_size)   \n",
    "autoencoder.compile(loss='mse', optimizer='Adam')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T20:21:36.224855Z",
     "start_time": "2020-11-13T20:21:36.035385Z"
    }
   },
   "source": [
    "tf.keras.utils.plot_model(autoencoder, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:56:58.158558Z",
     "start_time": "2020-11-14T15:56:58.145593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5785"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.samples // train_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `max_queue_size=10`, `use_multiprocessing=True`, `workers=16` Only used if Generator is instance of **SEQUENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:56:58.174555Z",
     "start_time": "2020-11-14T15:56:58.160553Z"
    }
   },
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = train_generator.samples // train_generator.batch_size\n",
    "STEP_SIZE_VALID = validation_generator.samples // validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T16:08:18.090093Z",
     "start_time": "2020-11-14T15:56:58.175512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5784/5785 [============================>.] - ETA: 0s - loss: 0.4962WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5785/5785 [==============================] - 307s 53ms/step - loss: 0.4963 - val_loss: 0.4932\n",
      "Epoch 2/2\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5784/5785 [============================>.] - ETA: 0s - loss: 0.4927WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5785/5785 [==============================] - 318s 55ms/step - loss: 0.4927 - val_loss: 0.4925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                       min_delta=0,\n",
    "                                       patience=5,\n",
    "                                       verbose=1, \n",
    "                                       mode='auto')'''\n",
    "\n",
    "#from tensorflow.keras.callbacks import CSVLogger, ProgbarLogger\n",
    "#csv_logger = CSVLogger('CHECKtraining.log')\n",
    "\n",
    "#tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "  \n",
    "start = time.time()\n",
    "    \n",
    "autoencoder_train = autoencoder.fit(train_generator,\n",
    "                                    epochs=2, \n",
    "                                    steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                                    validation_data = validation_generator, \n",
    "                                    validation_steps = STEP_SIZE_VALID,\n",
    "                                    verbose=1,\n",
    "                                    max_queue_size=15,\n",
    "                                    use_multiprocessing=True,\n",
    "                                    workers=12\n",
    "                                   )\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T16:08:18.106052Z",
     "start_time": "2020-11-14T16:08:18.092089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679.8946011066437"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T16:08:18.548896Z",
     "start_time": "2020-11-14T16:08:18.203791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(autoencoder_train.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T16:08:18.704453Z",
     "start_time": "2020-11-14T16:08:18.550863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(2)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Generator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Generator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#predict\n",
    "test_generator = DataGenerator(test_files, **params, to_fit=False)\n",
    "pred = model.predict_generator(pred_generator)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:56:22.753951Z",
     "start_time": "2020-11-12T17:56:22.739975Z"
    }
   },
   "source": [
    "### Example of what generators returns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:48:26.099513Z",
     "start_time": "2020-11-13T12:31:55.157Z"
    }
   },
   "source": [
    "def blank_out(img, percentage=0.05, square = True):\n",
    "    import numpy as np\n",
    "    \n",
    "    img = img.copy()\n",
    "    blank_out_size =  int(np.prod(img.shape) * percentage)\n",
    "    if not square:\n",
    "        max_side_size = img.shape[0]\n",
    "        min_side_size = np.ceil(blank_out_size/img.shape[0])+1\n",
    "        \n",
    "        heigth = np.random.randint(min_side_size, max_side_size) \n",
    "        width = int(np.floor(blank_out_size / heigth))\n",
    "        \n",
    "    else:\n",
    "        heigth = int(np.floor(np.sqrt(blank_out_size)))\n",
    "        width = heigth\n",
    "    \n",
    "    y_init_lim = np.random.randint(0, img.shape[0]-heigth)\n",
    "    x_init_lim = np.random.randint(0, img.shape[1]-width)\n",
    "    \n",
    "    img[y_init_lim : y_init_lim+heigth, x_init_lim : x_init_lim+width] = img.min()\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:35:44.960195Z",
     "start_time": "2020-11-13T13:35:44.817644Z"
    }
   },
   "source": [
    "params = {'dim': (256,256),\n",
    "          'batch_size': 2,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True,\n",
    "          'std_normalization': True,\n",
    "          'to_fit': True,\n",
    "          'augment': True,\n",
    "          'f_aug':blank_out,\n",
    "         }\n",
    "train_generator = DataGenerator(test_files, **params)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:48:26.101482Z",
     "start_time": "2020-11-13T12:31:55.161Z"
    }
   },
   "source": [
    "batchx, batchy = train_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:48:26.102479Z",
     "start_time": "2020-11-13T12:31:55.163Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:48:26.103488Z",
     "start_time": "2020-11-13T12:31:55.164Z"
    }
   },
   "source": [
    "for i in range(2):\n",
    "    fig, ax = plt.subplots(1,2,figsize = (12,4))\n",
    "    ax[0].imshow(batchx[i], cmap='gray')\n",
    "    ax[1].imshow(batchy[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T08:49:19.726710Z",
     "start_time": "2020-11-13T08:49:19.185261Z"
    }
   },
   "source": [
    "## OPTIMICE APPROACHS\n",
    "### Tf.Data\n",
    "https://www.tensorflow.org/guide/data_performance?hl=en\n",
    "\n",
    "https://towardsdatascience.com/dump-keras-imagedatagenerator-start-using-tensorflow-tf-data-part-2-fba7cda81203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T16:08:18.720408Z",
     "start_time": "2020-11-14T16:08:18.706445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T16:08:18.736365Z",
     "start_time": "2020-11-14T16:08:18.722403Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_using_tfdata(files, batch_size = 4, std_norm = True, cache_img=False):\n",
    "    \"\"\"\n",
    "    Load the images in batches using Tensorflow (tfdata).\n",
    "    Cache can be used to speed up the process.\n",
    "    Faster method in comparison to image loading using Keras.\n",
    "    Returns:\n",
    "    Data Generator to be used while training the model.\n",
    "    https://towardsdatascience.com/dump-keras-imagedatagenerator-start-using-tensorflow-tf-data-part-2-fba7cda81203\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    def parse_image(file_path):\n",
    "        # load the raw data from the file as a string\n",
    "        img = tf.cast(np.load(file_path.numpy()), tf.float32)\n",
    "        #img = tf.io.read_file(file_path)\n",
    "        img = tf.expand_dims(img, axis=2)\n",
    "        \n",
    "        #PREPROCESSING\n",
    "        # resize the image to the desired size.\n",
    "        # img = tf.image.resize(img, [img_dims[0], img_dims[1]], method=tf.image.ResizeMethod.GAUSSIAN, antialias=True)\n",
    "        if std_norm:\n",
    "            img = tf.math.divide(tf.math.subtract(img, tf.math.reduce_mean(img)),\n",
    "                                 tf.math.reduce_std(img))\n",
    "            \n",
    "        return img, tf.identity(img)\n",
    "        \n",
    "        #return tf.data.Dataset.zip((tf.data.Dataset.from_tensors(img), tf.data.Dataset.from_tensors(tf.identity(img))))\n",
    "\n",
    "\n",
    "    def prepare_for_training(ds, cache=False, shuffle_buffer_size=1000):\n",
    "        # If a small dataset, only load it once, and keep it in memory.\n",
    "        # use `.cache(filename)` to cache preprocessing work for datasets\n",
    "        # that don't fit in memory.\n",
    "        if cache:\n",
    "            if isinstance(cache, str):\n",
    "                ds = ds.cache(cache)\n",
    "            else:\n",
    "                ds = ds.cache()\n",
    "                \n",
    "        #https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle\n",
    "        ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "        \n",
    "        # representing the number of times the dataset should be repeated. \n",
    "        # The default behavior (if count is None or -1) is for the dataset be repeated indefinitely.\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.batch(batch_size)\n",
    "        \n",
    "        '''AUGMENTATION\n",
    "        aug_ds = train_ds.map(\n",
    "                          lambda x, y: (resize_and_rescale(x, training=True), y))'''\n",
    "        \n",
    "        # `prefetch` lets the dataset fetch batches in the background\n",
    "        # while the model is training.\n",
    "        ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    #Get all path files\n",
    "    list_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "    \n",
    "    # Set `num_parallel_calls` so that multiple images are\n",
    "    # processed in parallel\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    labeled_ds = list_ds.map(lambda item: tf.py_function(parse_image, [item],\n",
    "                                                                [tf.float32, tf.float32]),\n",
    "                                    num_parallel_calls=AUTOTUNE)\n",
    "    '''INTERLEAVE PARALELIZE\n",
    "    labeled_ds = list_ds.interleave(lambda item: tf.py_function(parse_image, [item],\n",
    "                                                                tf.float32),\n",
    "                                    num_parallel_calls=AUTOTUNE)'''\n",
    "    #labeled_ds = list_ds.interleave(tf.py_function(parse_image), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    # cache = True, False, './file_name'\n",
    "    # If the dataset doesn't fit in memory use a cache file,\n",
    "    # eg. cache='./data.tfcache'\n",
    "    \n",
    "    return prepare_for_training(labeled_ds, cache=cache_img) #'cocodata.tfcache'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T16:08:19.113357Z",
     "start_time": "2020-11-14T16:08:18.738362Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(8, 256, 256, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (8, 256, 256, 32)         320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (8, 256, 256, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (8, 128, 128, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (8, 128, 128, 64)         18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (8, 128, 128, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (8, 64, 64, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (8, 64, 64, 128)          73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (8, 64, 64, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (8, 64, 64, 64)           73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (8, 64, 64, 64)           256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (8, 128, 128, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (8, 128, 128, 32)         18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (8, 128, 128, 32)         128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (8, 256, 256, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (8, 256, 256, 1)          289       \n",
      "=================================================================\n",
      "Total params: 186,497\n",
      "Trainable params: 185,857\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "params = {'batch_size': GLOBAL_BATCH_SIZE,\n",
    "          'cache_img':False\n",
    "         }\n",
    "\n",
    "train_generator = load_data_using_tfdata(train_files, **params)\n",
    "validation_generator = load_data_using_tfdata(validation_files, **params)\n",
    "\n",
    "autoencoder =  build_model_2((256,256,1),  params.get('batch_size'))   \n",
    "autoencoder.compile(loss='mse', optimizer='Adam')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T16:08:19.129315Z",
     "start_time": "2020-11-14T16:08:19.115354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5785"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files) // params.get('batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T16:20:06.429260Z",
     "start_time": "2020-11-14T16:08:19.131310Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5785/5785 [==============================] - 351s 61ms/step - loss: 0.4962 - val_loss: 0.4929\n",
      "Epoch 2/2\n",
      "5785/5785 [==============================] - 353s 61ms/step - loss: 0.4926 - val_loss: 0.4917\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN = len(train_files) // params.get('batch_size')\n",
    "STEP_SIZE_VALID = len(validation_files) // params.get('batch_size')\n",
    "  \n",
    "start = time.time()\n",
    "    \n",
    "autoencoder_train = autoencoder.fit(train_generator,\n",
    "                                    epochs=2, \n",
    "                                    steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                                    validation_data = validation_generator, \n",
    "                                    validation_steps = STEP_SIZE_VALID,\n",
    "                                    verbose=1\n",
    "                                    #max_queue_size=15,\n",
    "                                    #use_multiprocessing=True,\n",
    "                                    #workers=12\n",
    "                                    \n",
    "                                   )\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T16:20:06.445218Z",
     "start_time": "2020-11-14T16:20:06.430258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707.2832615375519"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end-start"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.data.Dataset.range(2)\n",
    "    .interleave(\n",
    "        ArtificialDataset,\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d = Dataset.list_files(pattern)\n",
    "d = d.shard(num_workers, worker_index)\n",
    "d = d.repeat(num_epochs)\n",
    "d = d.shuffle(shuffle_buffer_size)\n",
    "d = d.interleave(tf.data.TFRecordDataset,\n",
    "                 cycle_length=num_readers, block_length=1)\n",
    "d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T20:05:49.999516Z",
     "start_time": "2020-11-13T20:05:49.981995Z"
    }
   },
   "source": [
    "tf.data.Dataset.zip((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGES - FROM PNG\n",
    "\n",
    "### Keras Flow_from_directory"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T14:47:57.460141Z",
     "start_time": "2020-11-14T14:47:57.452197Z"
    }
   },
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:11:15.012802Z",
     "start_time": "2020-11-14T15:11:12.140343Z"
    }
   },
   "source": [
    "train_datagen = ImageDataGenerator(samplewise_center=True,\n",
    "                                   samplewise_std_normalization=True,\n",
    "                                   #rescale = 0.5,\n",
    "                                   validation_split=1-train_percentage,\n",
    "                                   dtype=tf.float32\n",
    "                                  ) # OJO set validation split\n",
    "\n",
    "\n",
    "training_generator = train_datagen.flow_from_directory('..\\\\IXI-T1\\\\PNG\\\\train_val_folder\\\\',\n",
    "                                                 subset='training',\n",
    "                                                 class_mode='input', #OJOOOO,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size = (256,256),\n",
    "                                                 batch_size = GLOBAL_BATCH_SIZE)\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory('..\\\\IXI-T1\\\\PNG\\\\train_val_folder\\\\',\n",
    "                                                        subset='validation',\n",
    "                                                        class_mode='input', #OJOOOO\n",
    "                                                        color_mode='grayscale',\n",
    "                                                        target_size = (256,256),\n",
    "                                                        #interpolation\n",
    "                                                        batch_size = GLOBAL_BATCH_SIZE)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: training_generator, \n",
    "    output_types=(tf.float32, tf.float32), \n",
    "    output_shapes=([None,256,256,1], [None,256,256,1])\n",
    ")\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: validation_generator, \n",
    "    output_types=(tf.float32, tf.float32), \n",
    "    output_shapes=([None,256,256,1], [None,256,256,1])\n",
    ")\n",
    "\n",
    "def prepare_ds(ds):\n",
    "    #ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "    \n",
    "train_ds = prepare_ds(train_ds)\n",
    "val_ds = prepare_ds(val_ds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:11:39.101920Z",
     "start_time": "2020-11-14T15:11:38.964705Z"
    }
   },
   "source": [
    "autoencoder =  build_model_2((256,256,1),  GLOBAL_BATCH_SIZE)   \n",
    "autoencoder.compile(loss='mse', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:15:29.188651Z",
     "start_time": "2020-11-14T15:11:40.198870Z"
    }
   },
   "source": [
    "st = time.time()\n",
    "autoencoder.fit(train_ds, \n",
    "                epochs=2,\n",
    "                steps_per_epoch = (training_generator.samples // GLOBAL_BATCH_SIZE)-1,\n",
    "                \n",
    "                validation_data=val_ds,\n",
    "                validation_steps= (validation_generator.samples // GLOBAL_BATCH_SIZE)-1,\n",
    "                \n",
    "                #max_queue_size=15,\n",
    "                use_multiprocessing=True,\n",
    "                workers=12\n",
    "         )\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T15:00:54.021891Z",
     "start_time": "2020-11-14T15:00:12.164Z"
    }
   },
   "source": [
    "end - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF.Data a mano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAUG: https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb?hl=es#scrollTo=R5fGVMqlFxF7\n",
    "TOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T17:52:18.694377Z",
     "start_time": "2020-11-14T17:52:18.670427Z"
    }
   },
   "source": [
    "```python\n",
    "def load_img_data_using_tfdata(files, batch_size = 4, std_norm = True, cache_img=False):\n",
    "\n",
    "    def parse_image(file_path):\n",
    "        # load the raw data from the file as a string\n",
    "        img = tf.io.read_file(file_path)\n",
    "        # convert the compressed string to a 3D float tensor\n",
    "        img = tf.io.decode_png(img, channels=1)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        #PREPROCESSING\n",
    "        # resize the image to the desired size.\n",
    "        # img = tf.image.resize(img, [img_dims[0], img_dims[1]], method=tf.image.ResizeMethod.GAUSSIAN, antialias=True)\n",
    "        if std_norm:\n",
    "            img = tf.math.divide(tf.math.subtract(img, tf.math.reduce_mean(img)),\n",
    "                                 tf.math.reduce_std(img))\n",
    "        return img, tf.identity(img)\n",
    "        \n",
    "\n",
    "    def prepare_for_training(ds, cache=False, shuffle_buffer_size=1000):\n",
    "        if cache:\n",
    "            if isinstance(cache, str):\n",
    "                ds = ds.cache(cache)\n",
    "            else:\n",
    "                ds = ds.cache()       \n",
    "        #HERE preprocessing\n",
    "        ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "        ds = ds.repeat()\n",
    "        #HERE Augmentation that works with one image at a time \n",
    "        ds = ds.batch(batch_size)\n",
    "        #HERE AUGMENTATION works on batches ON CPU - Better option: first layers of model\n",
    "        ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    list_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    labeled_ds = list_ds.map(parse_image, num_parallel_calls=AUTOTUNE)\n",
    "    return prepare_for_training(labeled_ds, cache=cache_img)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T18:26:18.900531Z",
     "start_time": "2020-11-14T18:25:57.225730Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(8, 256, 256, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (8, 256, 256, 32)         320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (8, 256, 256, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (8, 128, 128, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (8, 128, 128, 64)         18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (8, 128, 128, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (8, 64, 64, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (8, 64, 64, 128)          73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (8, 64, 64, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (8, 64, 64, 64)           73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (8, 64, 64, 64)           256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (8, 128, 128, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (8, 128, 128, 32)         18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (8, 128, 128, 32)         128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (8, 256, 256, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (8, 256, 256, 1)          289       \n",
      "=================================================================\n",
      "Total params: 186,497\n",
      "Trainable params: 185,857\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "   1/5785 [..............................] - ETA: 3:50 - loss: 1.3627WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.0419s). Check your callbacks.\n",
      " 481/5785 [=>............................] - ETA: 3:40 - loss: 0.5122"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-bf70cc8cf69b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m                                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                                     \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                                     \u001b[1;31m#max_queue_size=15,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                                     \u001b[1;31m#use_multiprocessing=True,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \"\"\"\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuario\\.conda\\envs\\d_mri_autoencoder\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAIN_img_PATH = '..'+os.path.sep+'IXI-T1'+os.path.sep+'PNG'+os.path.sep+'train_val_folder'+os.path.sep+'train_and_val'\n",
    "trainval_img_files = glob.glob(MAIN_img_PATH+os.path.sep+'*.png')\n",
    "random.shuffle(trainval_img_files)\n",
    "\n",
    "lim = int(len(trainval_img_files)*train_percentage)\n",
    "train_img_files = trainval_img_files[:lim]\n",
    "validation_img_files = trainval_img_files[lim:]\n",
    "\n",
    "test_img_files = glob.glob('..\\\\IXI-T1\\\\PNG\\\\test_folder\\\\test\\\\*.png')\n",
    "\n",
    "params = {'batch_size': GLOBAL_BATCH_SIZE,\n",
    "          'cache':False,\n",
    "          'shuffle_buffer_size':1000\n",
    "         }\n",
    "\n",
    "trainds = tf_data_png_loader(train_img_files, \n",
    "                             **params\n",
    "                            ).get_tf_ds_generator()\n",
    "\n",
    "validation_ds = tf_data_png_loader(validation_img_files, \n",
    "                             **params\n",
    "                            ).get_tf_ds_generator()\n",
    "\n",
    "autoencoder =  build_model_2((256,256,1),  params.get('batch_size'))   \n",
    "autoencoder.compile(loss='mse', optimizer='Adam')\n",
    "autoencoder.summary()\n",
    "STEP_SIZE_TRAIN = len(train_files) // params.get('batch_size')\n",
    "STEP_SIZE_VALID = len(validation_files) // params.get('batch_size')\n",
    "  \n",
    "start = time.time()\n",
    "    \n",
    "autoencoder_train = autoencoder.fit(train_ds,\n",
    "                                    epochs=2, \n",
    "                                    steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                                    validation_data = validation_ds, \n",
    "                                    validation_steps = STEP_SIZE_VALID,\n",
    "                                    verbose=1\n",
    "                                    #max_queue_size=15,\n",
    "                                    #use_multiprocessing=True,\n",
    "                                    #workers=12\n",
    "                                    \n",
    "                                   )\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T17:02:18.080297Z",
     "start_time": "2020-11-14T17:02:18.062345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512.9202103614807"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorpack\n",
    "https://tensorpack.readthedocs.io/tutorial/extend/input-source.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T17:03:18.296576Z",
     "start_time": "2020-11-14T17:03:18.182207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([0,1,2],[679,707,512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T18:20:31.860608Z",
     "start_time": "2020-11-14T18:20:31.671498Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "201px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
