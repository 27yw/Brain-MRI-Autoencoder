{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalation and set up Tensorflow and Keras with CUDA\n",
    "\n",
    "In this notebook we will explain how to install tensorflow and keras, using the configuration for GPU using.\n",
    "\n",
    "Clink link for [Pytorch Instalation](https://medium.com/@_willfalcon/how-to-install-pytorch-1-0-with-cuda-10-0-169569c5b82d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. System requirements and general Steps\n",
    "\n",
    "* Your system has GPU Nvidia\n",
    "* You have installed CUDA (in this case 10.1) $\\rightarrow$ Visual Studio Express must be intalled in Windows\n",
    "* You have installed CUDnn  (in this case cudnn-10.1-windows10-x64-v7.6.5.32)\n",
    "* You have installed an Anaconda distribution (in this case: Miniconda)\n",
    "* You have installed the GPU version of tensorflow\n",
    "* Verify that tensorflow is running with GPU check if GPU is working\n",
    "\n",
    "**CUDA, Cudnn, and tensorflow-gpu versions must be compatible with each others.**\n",
    "\n",
    "**First of all ensure our system has Nvidia GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 02 12:08:40 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 456.38       Driver Version: 456.38       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 166... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   49C    P8     8W /  N/A |    600MiB /  6144MiB |     19%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2188    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      3284    C+G   ...mmandCenterBackground.exe    N/A      |\n",
      "|    0   N/A  N/A      4864    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      6920    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      8520    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      9736    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
      "|    0   N/A  N/A     11396    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11724    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     13184    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     15308    C+G   ...qxf38zg5c\\Skype\\Skype.exe    N/A      |\n",
      "|    0   N/A  N/A     15340    C+G   ...ystemEventUtilityHost.exe    N/A      |\n",
      "|    0   N/A  N/A     16060    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     16676    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     17884    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CUDA 10.1 Instalation\n",
    "\n",
    "* **Download VISUAL STUDIO EXPRESS 2019**\n",
    "\n",
    "Its necessary install [VSExpress](https://visualstudio.microsoft.com/es/vs/express/) for getting the properly base C++ files and libraries. We do have to install **C++ Workloads**.\n",
    "\n",
    "* **Download CUDA 10.1**\n",
    "\n",
    "Once installed VSE, we will [Download CUDA Toolkit 10.1 from its official page](https://developer.nvidia.com/cuda-10.1-download-archive-base?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exelocal). We can choose our OS, architecture, and download options (net or local).\n",
    "\n",
    "We must know the exact installation location of Cuda Toolkit, such as `C:\\Program Files\\NVIDA GPU Computing Toolkit\\CUDA\\v10.1`. We mus know it for adding it to the PATH.\n",
    "\n",
    "We will add `C:\\Program Files\\NVIDA GPU Computing Toolkit\\CUDA\\v10.1\\bin` and `C:\\Program Files\\NVIDA GPU Computing Toolkit\\CUDA\\v10.1\\libnvvp` to the Enviroment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.105\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. cuDNN 7.6.5 for CUDA 10.1 installation\n",
    "\n",
    "* **Install cuDNN 7.6.5 for CUDA 10.1**\n",
    "\n",
    "(cudnn-10.1-windows10-x64-v7.6.5.32)\n",
    "\n",
    "We should [download the zip for cuDNN](https://developer.nvidia.com/rdp/cudnn-download#). We must be loged in orde to be able to download it.\n",
    "\n",
    "We will click [Archived cuDNN Releases](https://developer.nvidia.com/rdp/cudnn-archive) and choose *Download cuDNN v7.6.5 (November 5th, 2019), for CUDA 10.1*\n",
    "\n",
    "It is not an executable, **we must copy the proper files from cuDNN zip to our local CUDA PATH**.\n",
    "\n",
    "\n",
    "| Source  |   | Target  |\n",
    "|---|---|---|\n",
    "| <downloadpath\\>\\cudnn-10.1-windows10-x64-v7.6.5.32\\cuda\\bin\\\\**cudnn64_7.dll**  |  $\\rightarrow$ | <cudapath\\>NVIDA GPU Computing Toolkit\\CUDA\\v10.1\\bin\\  |\n",
    "| <downloadpath\\>\\cudnn-10.1-windows10-x64-v7.6.5.32\\cuda\\include\\\\**cudnn.h**  |  $\\rightarrow$ | <cudapath\\>NVIDA GPU Computing Toolkit\\CUDA\\v10.1\\include\\  |   \n",
    "| <downloadpath\\>\\cudnn-10.1-windows10-x64-v7.6.5.32\\cuda\\lib\\x64\\\\**cudnn.lib**  |  $\\rightarrow$ | <cudapath\\>NVIDA GPU Computing Toolkit\\CUDA\\v10.1\\lib\\x64\\  |  \n",
    "    \n",
    "**Ensure cudnn64_7.dll file exists**. In some new versions, you have cudnn64_8.dll instead, and TF crashes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install tensorflow-gpu\n",
    "\n",
    "`pip instal tensorflow-gpu` or `pip instal tensorflow-gpu==version`\n",
    "\n",
    "It works for versions 2.1.0 and 2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "\n",
    "## 4. Checking if system recognices GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Checking (in many ways) if tensorflow recognice GPU\n",
    "\n",
    "In [Tensorflow Guide for use of GPU](https://www.tensorflow.org/guide/gpu) They cover more topics like\n",
    "\n",
    "* Limit GPU usage and dynamic growth.\n",
    "* Dynamically selection of device.\n",
    "* Usage of multiples GPU: **SIMULATE IN A 1-GPU SYSTEM**.\n",
    "\n",
    "\n",
    "**TensorFlow code, and tf.keras models will transparently run on a single GPU with no code changes required.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fist of all, we show the tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the distribution of Tensorflow is intalled with gpu availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some commands that show us if GPU is seen by tensorflow (and hence Cuda, CuDnn, and Tensorflow-gpu properly installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-78f884b5c1a9>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_logical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7217021839371242892,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 10241166872665323710\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 4973462816\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 16761669919385134732\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 16966958974781054450\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all devices with its details\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logging device placement**\n",
    "\n",
    "To find out which devices your operations and tensors are assigned to, put tf.debugging.set_log_device_placement(True) as the first statement of your program. Enabling device placement logging causes any Tensor allocations or operations to be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set log in older versions\n",
    "#sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of running: see miniconda prompt for log output or jupyter cell output.\n",
    "\n",
    "*Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case of Tensorflow doesn't run it on GPU, we could set up manualy**\n",
    "\n",
    "Manual device placement\n",
    "```python \n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Place tensors on the CPU\n",
    "with tf.device('/CPU:0'): #with tf.device('/device:GPU:0'):\n",
    "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "# Run on the GPU\n",
    "c = tf.matmul(a, b)\n",
    "print(c)\n",
    "```\n",
    "\n",
    "You will see that now a and b are assigned to CPU:0. Since a device was not explicitly specified for the MatMul operation, the TensorFlow runtime will choose one based on the operation and available devices (GPU:0 in this example) and automatically copy tensors between devices if required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Keras\n",
    "\n",
    "In Tensorflow Keras is already bult-in. Therefore, the use and configuration of GPU is madre through Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Checking if Pytorch recognice it\n",
    "In case of having Pythorch installed\n",
    "```python\n",
    "# confirm PyTorch sees the GPU\n",
    "from torch import cuda\n",
    "cuda.is_available()\n",
    "cuda.device_count() > 0\n",
    "print(cuda.get_device_name(cuda.current_device()))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example Experiment\n",
    "To ensure that Keras and Tensorflow are using the GPU, we are making a little demo model and check the GPU usage.\n",
    "\n",
    "We will compare the execution time of a toy model (mnist classification) executing on CPU vs GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2444 - accuracy: 0.9247 - val_loss: 0.1093 - val_accuracy: 0.9658\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1044 - accuracy: 0.9683 - val_loss: 0.0815 - val_accuracy: 0.9748\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0778 - accuracy: 0.9761 - val_loss: 0.0748 - val_accuracy: 0.9788\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9828 - val_loss: 0.0760 - val_accuracy: 0.9796\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9857 - val_loss: 0.0736 - val_accuracy: 0.9808\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0428 - accuracy: 0.9870 - val_loss: 0.0764 - val_accuracy: 0.9809\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0387 - accuracy: 0.9890 - val_loss: 0.0785 - val_accuracy: 0.9819\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 0.0830 - val_accuracy: 0.9825\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0311 - accuracy: 0.9910 - val_loss: 0.0899 - val_accuracy: 0.9813\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 0.0809 - val_accuracy: 0.9834\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0273 - accuracy: 0.9923 - val_loss: 0.0916 - val_accuracy: 0.9838\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.0908 - val_accuracy: 0.9840\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.0908 - val_accuracy: 0.9832\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0886 - val_accuracy: 0.9852\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0224 - accuracy: 0.9937 - val_loss: 0.0959 - val_accuracy: 0.9818\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.1040 - val_accuracy: 0.9855\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.1029 - val_accuracy: 0.9846\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.1328 - val_accuracy: 0.9840\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.1161 - val_accuracy: 0.9848\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.1170 - val_accuracy: 0.9856\n",
      "Test loss: 0.11704614013433456\n",
      "Test accuracy: 0.9855999946594238\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "''' Not built-in Keras\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop'''\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import time\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "s_time = time.time()\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.41860294342041"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - s_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2498 - accuracy: 0.9239 - val_loss: 0.1058 - val_accuracy: 0.9666\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1028 - accuracy: 0.9693 - val_loss: 0.0845 - val_accuracy: 0.9750\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0751 - accuracy: 0.9776 - val_loss: 0.0760 - val_accuracy: 0.9789\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0608 - accuracy: 0.9823 - val_loss: 0.0699 - val_accuracy: 0.9803\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0492 - accuracy: 0.9850 - val_loss: 0.0760 - val_accuracy: 0.9813\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.0756 - val_accuracy: 0.9809\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0377 - accuracy: 0.9889 - val_loss: 0.0732 - val_accuracy: 0.9820\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.0723 - val_accuracy: 0.9840\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.0885 - val_accuracy: 0.9830\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0277 - accuracy: 0.9920 - val_loss: 0.0898 - val_accuracy: 0.9830\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0259 - accuracy: 0.9925 - val_loss: 0.1006 - val_accuracy: 0.9842\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0227 - accuracy: 0.9935 - val_loss: 0.0860 - val_accuracy: 0.9846\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0881 - val_accuracy: 0.9840\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.1053 - val_accuracy: 0.9831\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.1233 - val_accuracy: 0.9820\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.1098 - val_accuracy: 0.9836\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.1203 - val_accuracy: 0.9834\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.1349 - val_accuracy: 0.9823\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.1323 - val_accuracy: 0.9824\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.1201 - val_accuracy: 0.9835\n",
      "Test loss: 0.12009309232234955\n",
      "Test accuracy: 0.9835000038146973\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2456 - accuracy: 0.9249 - val_loss: 0.1030 - val_accuracy: 0.9665\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1016 - accuracy: 0.9693 - val_loss: 0.0990 - val_accuracy: 0.9704\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0753 - accuracy: 0.9771 - val_loss: 0.0800 - val_accuracy: 0.9767\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.9817 - val_loss: 0.0785 - val_accuracy: 0.9790\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 0.0689 - val_accuracy: 0.9818\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0440 - accuracy: 0.9866 - val_loss: 0.0811 - val_accuracy: 0.9785\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9888 - val_loss: 0.0953 - val_accuracy: 0.9785\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0335 - accuracy: 0.9899 - val_loss: 0.0806 - val_accuracy: 0.9817\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9913 - val_loss: 0.0807 - val_accuracy: 0.9841\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.9914 - val_loss: 0.0967 - val_accuracy: 0.9814\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 0.1138 - val_accuracy: 0.9789\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 0.1034 - val_accuracy: 0.9830\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.1038 - val_accuracy: 0.9831\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0226 - accuracy: 0.9938 - val_loss: 0.1015 - val_accuracy: 0.9822\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.1077 - val_accuracy: 0.9828\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.1242 - val_accuracy: 0.9824\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.1107 - val_accuracy: 0.9839\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.1354 - val_accuracy: 0.9821\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.1259 - val_accuracy: 0.9843\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.1369 - val_accuracy: 0.9812\n",
      "Test loss: 0.13688459992408752\n",
      "Test accuracy: 0.9811999797821045\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "time_execution = dict()\n",
    "\n",
    "for dev in [d for d in tf.config.experimental.list_logical_devices() if not 'XLA' in d.name]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    with tf.device(dev.name):\n",
    "\n",
    "        batch_size = 128\n",
    "        num_classes = 10\n",
    "        epochs = 20\n",
    "\n",
    "        # the data, shuffled and split between train and test sets\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        x_train = x_train.reshape(60000, 784)\n",
    "        x_test = x_test.reshape(10000, 784)\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "        print(x_train.shape[0], 'train samples')\n",
    "        print(x_test.shape[0], 'test samples')\n",
    "\n",
    "        # convert class vectors to binary class matrices\n",
    "        y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=RMSprop(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_test, y_test))\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        \n",
    "        time_execution[dev.device_type] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CPU': 76.77355575561523, 'GPU': 28.334858179092407}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
